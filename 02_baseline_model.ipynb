{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 The objective of this notebook is to train and test a baseline model - Logistic Regression"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We only want to focus on the dissatisfied clients, so we can identify the problems here. So, we will aim for the metric that cares about the negatives outcomes 0.\n",
    "For this, we will focus on the specificity.\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference metric: 73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------Importing libraries---------#\n",
    "\n",
    "#---Data analysis---#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#---Data splitting---#\n",
    "from sklearn.model_selection import train_test_split\n",
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#---classification models---#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#---evaluation---#\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "\n",
    "#---utils---#\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity_score(y_test, y_pred):\n",
    "    tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    print('Specificity score: {:.2%} '.format(specificity))\n",
    "\n",
    "\n",
    "\n",
    "# Create the custom scoring function\n",
    "specificity_scorer = make_scorer(specificity_score)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing raw data\n",
    "df = pd.read_csv('data/ACME-HappinessSurvey2020.csv')\n",
    "\n",
    "#splitting data into 80% train and 20% test\n",
    "X = df.drop(columns=['Y'])\n",
    "y = df['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 46.15% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.33      0.42        15\n",
      "           1       0.41      0.64      0.50        11\n",
      "\n",
      "    accuracy                           0.46        26\n",
      "   macro avg       0.48      0.48      0.46        26\n",
      "weighted avg       0.49      0.46      0.45        26\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity score: 33.33% \n"
     ]
    }
   ],
   "source": [
    "specificity_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, our baseline is 46% accuracy. Let's see if we can do better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "df_v1 = pd.read_csv('data/base_v1.csv')\n",
    "\n",
    "#splitting data into 80% train and 20% test\n",
    "X = df_v1.drop(columns=['Y'])\n",
    "y = df_v1['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df_v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 72.73% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.50      0.62        10\n",
      "           1       0.69      0.92      0.79        12\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.76      0.71      0.71        22\n",
      "weighted avg       0.75      0.73      0.71        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72.7% ! almost a 30% improvement over the baseline. Let's see if we can do better with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity score: 50.00% \n"
     ]
    }
   ],
   "source": [
    "specificity_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: X1, Score: 0.43\n",
      "Feature: X2, Score: -0.12\n",
      "Feature: X3, Score: 0.23\n",
      "Feature: X4, Score: -0.09\n",
      "Feature: X5, Score: 0.07\n",
      "Feature: X6, Score: 0.35\n"
     ]
    }
   ],
   "source": [
    "#features importances\n",
    "\n",
    "importance = LR.coef_[0]\n",
    "# summarize feature importance\n",
    "for col, values in zip(X.columns, importance):\n",
    "    print('Feature: %s, Score: %.2f' % (col, values))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, by the correlation map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.1 Traning with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity score: 50.00% \n",
      "Specificity score: 20.00% \n",
      "Specificity score: 60.00% \n",
      "Specificity score: 44.44% \n",
      "Specificity score: 11.11% \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#traning with cross validation, k=5\n",
    "\n",
    "LR = LogisticRegression(random_state=42)\n",
    "scores = cross_val_score(LR, X, y, cv=5, scoring=specificity_scorer)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "df_v2 = pd.read_csv('data/base_v2.csv')\n",
    "\n",
    "#splitting data into 80% train and 20% test\n",
    "X = df_v2.drop(columns=['Y'])\n",
    "y = df_v2['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 63.64% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        10\n",
      "           1       0.67      0.67      0.67        12\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.63      0.63      0.63        22\n",
      "weighted avg       0.64      0.64      0.64        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, not good to try and remove features that are bad correlated with target. ( Why? )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "df= pd.read_csv('data/base_v3.csv')\n",
    "\n",
    "#splitting data into 80% train and 20% test\n",
    "X = df.drop(columns=['Y'])\n",
    "y = df['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 54.55% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.30      0.37        10\n",
      "           1       0.56      0.75      0.64        12\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.53      0.53      0.51        22\n",
      "weighted avg       0.53      0.55      0.52        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Data version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "df= pd.read_csv('data/base_v4.csv')\n",
    "\n",
    "#splitting data into 80% train and 20% test\n",
    "X = df.drop(columns=['Y'])\n",
    "y = df['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 68.18% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        10\n",
      "           1       0.69      0.75      0.72        12\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.68      0.68      0.68        22\n",
      "weighted avg       0.68      0.68      0.68        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data version 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "df= pd.read_csv('data/base_v5.csv')\n",
    "\n",
    "#splitting data into 80% train and 20% test\n",
    "X = df.drop(columns=['Y'])\n",
    "y = df['Y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 68.18% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        10\n",
      "           1       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.69      0.67      0.66        22\n",
      "weighted avg       0.69      0.68      0.67        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(random_state=42)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good try, but not good enough."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data version 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(1,7):\n",
    "    dfs.append(pd.read_csv('data/base_v6_X{}.csv'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base line Accuracy score: 63.64% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.40      0.50        10\n",
      "           1       0.62      0.83      0.71        12\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.65      0.62      0.61        22\n",
      "weighted avg       0.64      0.64      0.62        22\n",
      "\n",
      "Base line Accuracy score: 68.18% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        10\n",
      "           1       0.69      0.75      0.72        12\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.68      0.68      0.68        22\n",
      "weighted avg       0.68      0.68      0.68        22\n",
      "\n",
      "Base line Accuracy score: 68.18% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        10\n",
      "           1       0.67      0.83      0.74        12\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.69      0.67      0.66        22\n",
      "weighted avg       0.69      0.68      0.67        22\n",
      "\n",
      "Base line Accuracy score: 72.73% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        10\n",
      "           1       0.71      0.83      0.77        12\n",
      "\n",
      "    accuracy                           0.73        22\n",
      "   macro avg       0.73      0.72      0.72        22\n",
      "weighted avg       0.73      0.73      0.72        22\n",
      "\n",
      "Base line Accuracy score: 68.18% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        10\n",
      "           1       0.69      0.75      0.72        12\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.68      0.68      0.68        22\n",
      "weighted avg       0.68      0.68      0.68        22\n",
      "\n",
      "Base line Accuracy score: 68.18% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.40      0.53        10\n",
      "           1       0.65      0.92      0.76        12\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.72      0.66      0.65        22\n",
      "weighted avg       0.72      0.68      0.66        22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    #splitting data into 80% train and 20% test\n",
    "    X = df.drop(columns=['Y'])\n",
    "    y = df['Y']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    LR = LogisticRegression(random_state=42)\n",
    "    LR.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = LR.predict(X_test)\n",
    "\n",
    "    print('Base line Accuracy score: {:.2%} '.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
